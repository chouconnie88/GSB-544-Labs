{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c8c8af16-6283-4784-bd90-b1c8cf518fae",
   "metadata": {},
   "source": [
    "---\n",
    "self-contained: true\n",
    "title: \"Lab 6 Baseball salaries\"\n",
    "format:\n",
    "  html:\n",
    "    theme: litera\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922e2232-b90a-4909-9e94-707e71a8456b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2c80e-d976-4ca9-bc82-fd5fa0e7800a",
   "metadata": {},
   "source": [
    "# Part 0: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359124c2-3dbf-4648-be62-1039ae83b141",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>446</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "0      293    66      1    30   29     14      1     293     66       1   \n",
       "1      315    81      7    24   38     39     14    3449    835      69   \n",
       "2      479   130     18    66   72     76      3    1624    457      63   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39   \n",
       "319    475   126      3    61   43     52      6    1700    433       7   \n",
       "320    573   144      9    85   60     78      8    3198    857      97   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30   \n",
       "\n",
       "     CRuns  CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary  \\\n",
       "0       30    29      14      A        E      446       33      20     NaN   \n",
       "1      321   414     375      N        W      632       43      10   475.0   \n",
       "2      224   266     263      A        W      880       82      14   480.0   \n",
       "3      828   838     354      N        E      200       11       3   500.0   \n",
       "4       48    46      33      N        E      805       40       4    91.5   \n",
       "..     ...   ...     ...    ...      ...      ...      ...     ...     ...   \n",
       "317    379   311     138      N        E      325        9       3   700.0   \n",
       "318    897   451     875      A        E      313      381      20   875.0   \n",
       "319    217    93     146      A        W       37      113       7   385.0   \n",
       "320    470   420     332      A        E     1314      131      12   960.0   \n",
       "321    775   357     249      A        W      408        4       3  1000.0   \n",
       "\n",
       "    NewLeague  \n",
       "0           A  \n",
       "1           N  \n",
       "2           A  \n",
       "3           N  \n",
       "4           N  \n",
       "..        ...  \n",
       "317         N  \n",
       "318         A  \n",
       "319         A  \n",
       "320         A  \n",
       "321         A  \n",
       "\n",
       "[322 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data set\n",
    "hitters = pd.read_csv(\"/Users/conniechou/Library/CloudStorage/OneDrive-Personal/Connie/Homework/GSB544_Bodwin/Labs/Hitters.csv\")\n",
    "hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db475c8-665e-420a-b08d-b31b4d936ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat          int64\n",
       "Hits           int64\n",
       "HmRun          int64\n",
       "Runs           int64\n",
       "RBI            int64\n",
       "Walks          int64\n",
       "Years          int64\n",
       "CAtBat         int64\n",
       "CHits          int64\n",
       "CHmRun         int64\n",
       "CRuns          int64\n",
       "CRBI           int64\n",
       "CWalks         int64\n",
       "League        object\n",
       "Division      object\n",
       "PutOuts        int64\n",
       "Assists        int64\n",
       "Errors         int64\n",
       "Salary       float64\n",
       "NewLeague     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c1abf-e11f-4392-b274-94d26cc36f0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "All variable types look ok. Salary (dependent variable) is in float. League, Division, and NewLeague are categorical variables, so they are object type. Everything else is numerical integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4bf68ee-95b9-4a4c-ae97-e8bd46254278",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>497</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2703</td>\n",
       "      <td>806</td>\n",
       "      <td>32</td>\n",
       "      <td>379</td>\n",
       "      <td>311</td>\n",
       "      <td>138</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>492</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>50</td>\n",
       "      <td>94</td>\n",
       "      <td>12</td>\n",
       "      <td>5511</td>\n",
       "      <td>1511</td>\n",
       "      <td>39</td>\n",
       "      <td>897</td>\n",
       "      <td>451</td>\n",
       "      <td>875</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>313</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>875.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>475</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>1700</td>\n",
       "      <td>433</td>\n",
       "      <td>7</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>146</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>385.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>3198</td>\n",
       "      <td>857</td>\n",
       "      <td>97</td>\n",
       "      <td>470</td>\n",
       "      <td>420</td>\n",
       "      <td>332</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>1314</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>960.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>631</td>\n",
       "      <td>170</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>4908</td>\n",
       "      <td>1457</td>\n",
       "      <td>30</td>\n",
       "      <td>775</td>\n",
       "      <td>357</td>\n",
       "      <td>249</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>408</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  \\\n",
       "1      315    81      7    24   38     39     14    3449    835      69   \n",
       "2      479   130     18    66   72     76      3    1624    457      63   \n",
       "3      496   141     20    65   78     37     11    5628   1575     225   \n",
       "4      321    87     10    39   42     30      2     396    101      12   \n",
       "5      594   169      4    74   51     35     11    4408   1133      19   \n",
       "..     ...   ...    ...   ...  ...    ...    ...     ...    ...     ...   \n",
       "317    497   127      7    65   48     37      5    2703    806      32   \n",
       "318    492   136      5    76   50     94     12    5511   1511      39   \n",
       "319    475   126      3    61   43     52      6    1700    433       7   \n",
       "320    573   144      9    85   60     78      8    3198    857      97   \n",
       "321    631   170      9    77   44     31     11    4908   1457      30   \n",
       "\n",
       "     CRuns  CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary  \\\n",
       "1      321   414     375      N        W      632       43      10   475.0   \n",
       "2      224   266     263      A        W      880       82      14   480.0   \n",
       "3      828   838     354      N        E      200       11       3   500.0   \n",
       "4       48    46      33      N        E      805       40       4    91.5   \n",
       "5      501   336     194      A        W      282      421      25   750.0   \n",
       "..     ...   ...     ...    ...      ...      ...      ...     ...     ...   \n",
       "317    379   311     138      N        E      325        9       3   700.0   \n",
       "318    897   451     875      A        E      313      381      20   875.0   \n",
       "319    217    93     146      A        W       37      113       7   385.0   \n",
       "320    470   420     332      A        E     1314      131      12   960.0   \n",
       "321    775   357     249      A        W      408        4       3  1000.0   \n",
       "\n",
       "    NewLeague  \n",
       "1           N  \n",
       "2           A  \n",
       "3           N  \n",
       "4           N  \n",
       "5           A  \n",
       "..        ...  \n",
       "317         N  \n",
       "318         A  \n",
       "319         A  \n",
       "320         A  \n",
       "321         A  \n",
       "\n",
       "[263 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop na values\n",
    "hitters_df = hitters.dropna()\n",
    "hitters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c5680-1783-433e-86a9-bbaae378fdb6",
   "metadata": {},
   "source": [
    "# Part 1: Different Model Specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a47476-155a-4897-ae82-aef83e8e9fe4",
   "metadata": {},
   "source": [
    "## Regression without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d14afe-7130-4282-9866-4ca6be3ae96f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#defining our X and y in global environment because we want to use these for the entire lab\n",
    "X = hitters_df.drop([\"Salary\"], axis = 1)\n",
    "y = hitters_df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecaa1fd-e253-4388-b17f-ed40f1aead5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function of the general steps for different modeling types\n",
    "def model(regression_label, type_of_regression):\n",
    "    \n",
    "    \"\"\"\n",
    "    transforms columns and outputs a pipeline of the desired kind of regression model\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    regression_label : str\n",
    "    A string represeting the label of the modeling type\n",
    "    \n",
    "    type_of_regression: sklearn function\n",
    "    A specific function for the modeling type \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arrays \n",
    "    returns the pipeline of the specified type of model\n",
    "    \"\"\"\n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "    (\"dummify\",\n",
    "    OneHotEncoder(sparse_output = False, handle_unknown = \"ignore\"),\n",
    "    make_column_selector(dtype_include=object)), #selecting all columns that are categorical\n",
    "    (\"standardize\",\n",
    "    StandardScaler(),\n",
    "    make_column_selector(dtype_include=np.number)) #standardizing numerical variables\n",
    "    ], remainder = \"passthrough\" #keep everything else\n",
    "    )\n",
    "    \n",
    "    lr_pipeline = Pipeline(\n",
    "      [(\"preprocessing\", ct),\n",
    "      (regression_label, type_of_regression)]\n",
    "    ).set_output(transform = \"pandas\")\n",
    "    \n",
    "    return lr_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3825761-61bf-4a0e-bde4-620fb51b4e55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fitting pipeline onto ENTIRE dataset\n",
    "pipeline = model(regression_label = \"linear_regression\", type_of_regression = LinearRegression())\n",
    "fitted_pipeline = pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99d6083d-5868-404b-9c1b-bf3f5257dfe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -31.29971152,   31.29971152,   58.42462282,  -58.42462282,\n",
       "         12.38116255,  -12.38116255, -291.0945557 ,  337.83047948,\n",
       "         37.85383676,  -60.57247861,  -26.99498379,  135.07389695,\n",
       "        -16.69335888, -391.03865466,   86.68761664,  -14.18172332,\n",
       "        480.74713477,  260.68988581, -213.89225864,   78.76129639,\n",
       "         53.73248973,  -22.16086217])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefficients for linear model\n",
    "coeff = fitted_pipeline.named_steps[\"linear_regression\"].coef_\n",
    "coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1580aa6e-f691-4e39-827a-56319a791014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121136.31031816886"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross validation mse for linear model\n",
    "cross_val_scores = cross_val_score(pipeline, X, y, cv = 5, scoring = 'neg_mean_squared_error')\n",
    "-cross_val_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16440bd3-d607-4553-951a-a2b81b525b89",
   "metadata": {},
   "source": [
    "### The MSE I would expect to predict 1989 salaries is 121136.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b99baed-e7dc-474e-95ad-1fcffe54cbd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to find best coefficients\n",
    "def variable_names_df(pipeline_name, coefficient_list):\n",
    "    \"\"\"\n",
    "    creates a dataframe of the coefficients of the regression and their respective variable names\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    pipeline_name: variable\n",
    "    The fitted pipeline variable name\n",
    "    \n",
    "    coefficient_list: array\n",
    "    An array of the coefficients calculated using .name_steps[].coef_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas data frame \n",
    "    A data frame with coefficients and their variable names sorted in descending order by coefficients\n",
    "    \"\"\"\n",
    "    feature_names = pipeline_name[:-1].get_feature_names_out()\n",
    "    \n",
    "    coeff_var_df = pd.DataFrame({\"variable_name\": feature_names,\n",
    "                                 \"coefficients\": coefficient_list})\n",
    "    return coeff_var_df.sort_values(by = \"coefficients\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05239703-47f4-4a91-abda-ce91818571cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>480.747135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>337.830479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>260.689886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>135.073897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>86.687617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>standardize__PutOuts</td>\n",
       "      <td>78.761296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dummify__Division_E</td>\n",
       "      <td>58.424623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>standardize__Assists</td>\n",
       "      <td>53.732490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>standardize__HmRun</td>\n",
       "      <td>37.853837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dummify__League_N</td>\n",
       "      <td>31.299712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dummify__NewLeague_A</td>\n",
       "      <td>12.381163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dummify__NewLeague_N</td>\n",
       "      <td>-12.381163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>standardize__CHmRun</td>\n",
       "      <td>-14.181723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>standardize__Years</td>\n",
       "      <td>-16.693359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>standardize__Errors</td>\n",
       "      <td>-22.160862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>standardize__RBI</td>\n",
       "      <td>-26.994984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummify__League_A</td>\n",
       "      <td>-31.299712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummify__Division_W</td>\n",
       "      <td>-58.424623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>standardize__Runs</td>\n",
       "      <td>-60.572479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>standardize__CWalks</td>\n",
       "      <td>-213.892259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>standardize__AtBat</td>\n",
       "      <td>-291.094556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>standardize__CAtBat</td>\n",
       "      <td>-391.038655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           variable_name  coefficients\n",
       "16    standardize__CRuns    480.747135\n",
       "7      standardize__Hits    337.830479\n",
       "17     standardize__CRBI    260.689886\n",
       "11    standardize__Walks    135.073897\n",
       "14    standardize__CHits     86.687617\n",
       "19  standardize__PutOuts     78.761296\n",
       "2    dummify__Division_E     58.424623\n",
       "20  standardize__Assists     53.732490\n",
       "8     standardize__HmRun     37.853837\n",
       "1      dummify__League_N     31.299712\n",
       "4   dummify__NewLeague_A     12.381163\n",
       "5   dummify__NewLeague_N    -12.381163\n",
       "15   standardize__CHmRun    -14.181723\n",
       "12    standardize__Years    -16.693359\n",
       "21   standardize__Errors    -22.160862\n",
       "10      standardize__RBI    -26.994984\n",
       "0      dummify__League_A    -31.299712\n",
       "3    dummify__Division_W    -58.424623\n",
       "9      standardize__Runs    -60.572479\n",
       "18   standardize__CWalks   -213.892259\n",
       "6     standardize__AtBat   -291.094556\n",
       "13   standardize__CAtBat   -391.038655"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear regression data frame of coefficients and their variable labels\n",
    "lr_df = variable_names_df(fitted_pipeline, coeff)\n",
    "lr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8f8e6-2a1d-44ab-b8a8-5c910b161930",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016c95cf-182e-4b83-ae40-237c72bb3ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating ridge regression pipeline\n",
    "\n",
    "pipeline_r = model(regression_label = \"ridge_reg\", type_of_regression = Ridge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8093482b-c3e5-4d1c-bd23-ae9699f875ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating dictionary with different lambda values for tuning\n",
    "lambdas_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "lambdas = {'ridge_reg__alpha': lambdas_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv = GridSearchCV(pipeline_r, lambdas, cv = 5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a020bb4e-4370-4928-baf0-50171bf8047a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_ridge_reg__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>119144.432677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>119348.984776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>120343.621067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>121022.903286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>121124.458592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_ridge_reg__alpha  mean_test_score\n",
       "3                      1    119144.432677\n",
       "4                     10    119348.984776\n",
       "2                    0.1    120343.621067\n",
       "1                   0.01    121022.903286\n",
       "0                  0.001    121124.458592"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting gridsearchcv to entire dataset\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "ridge_df = pd.DataFrame(gscv_fitted.cv_results_)\n",
    "ridge_df = ridge_df[[\"param_ridge_reg__alpha\", \"mean_test_score\"]] #get the columns i want\n",
    "ridge_df[\"mean_test_score\"] = ridge_df[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "ridge_df.sort_values(by = \"mean_test_score\", ascending = True) #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35955508-9d9a-409d-be54-27bf91ac4798",
   "metadata": {},
   "source": [
    "### The model with the lambda value that equals 1 is the best model, since it has the lowest MSE value. The estimated MSE to predict 1989 salaries is 119144.432677."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c44dcf-7405-4a09-87cb-4b9851c023bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -30.43885531,   30.43885531,   60.01559493,  -60.01559493,\n",
       "         13.11128155,  -13.11128155, -270.6864407 ,  296.64505003,\n",
       "         18.10059158,  -29.33940613,   -9.11329453,  124.40717273,\n",
       "        -38.66774782, -225.40654798,  126.65960655,   39.07092364,\n",
       "        320.41216891,  160.38678418, -184.4236106 ,   78.62365619,\n",
       "         47.46259711,  -23.72419031])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit ridge regression model on entire data set using this lambda = 1\n",
    "pipeline_r_1 = model(regression_label = \"ridge_reg\", type_of_regression = Ridge(alpha = 1))\n",
    "fitted_pipeline_r = pipeline_r_1.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_r = fitted_pipeline_r.named_steps[\"ridge_reg\"].coef_\n",
    "coeff_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db2cc428-28e0-4e0f-9911-ad6e4a6bbc8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>320.412169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>296.645050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>160.386784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>126.659607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>124.407173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>standardize__PutOuts</td>\n",
       "      <td>78.623656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dummify__Division_E</td>\n",
       "      <td>60.015595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>standardize__Assists</td>\n",
       "      <td>47.462597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>standardize__CHmRun</td>\n",
       "      <td>39.070924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dummify__League_N</td>\n",
       "      <td>30.438855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>standardize__HmRun</td>\n",
       "      <td>18.100592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dummify__NewLeague_A</td>\n",
       "      <td>13.111282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>standardize__RBI</td>\n",
       "      <td>-9.113295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dummify__NewLeague_N</td>\n",
       "      <td>-13.111282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>standardize__Errors</td>\n",
       "      <td>-23.724190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>standardize__Runs</td>\n",
       "      <td>-29.339406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummify__League_A</td>\n",
       "      <td>-30.438855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>standardize__Years</td>\n",
       "      <td>-38.667748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummify__Division_W</td>\n",
       "      <td>-60.015595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>standardize__CWalks</td>\n",
       "      <td>-184.423611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>standardize__CAtBat</td>\n",
       "      <td>-225.406548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>standardize__AtBat</td>\n",
       "      <td>-270.686441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           variable_name  coefficients\n",
       "16    standardize__CRuns    320.412169\n",
       "7      standardize__Hits    296.645050\n",
       "17     standardize__CRBI    160.386784\n",
       "14    standardize__CHits    126.659607\n",
       "11    standardize__Walks    124.407173\n",
       "19  standardize__PutOuts     78.623656\n",
       "2    dummify__Division_E     60.015595\n",
       "20  standardize__Assists     47.462597\n",
       "15   standardize__CHmRun     39.070924\n",
       "1      dummify__League_N     30.438855\n",
       "8     standardize__HmRun     18.100592\n",
       "4   dummify__NewLeague_A     13.111282\n",
       "10      standardize__RBI     -9.113295\n",
       "5   dummify__NewLeague_N    -13.111282\n",
       "21   standardize__Errors    -23.724190\n",
       "9      standardize__Runs    -29.339406\n",
       "0      dummify__League_A    -30.438855\n",
       "12    standardize__Years    -38.667748\n",
       "3    dummify__Division_W    -60.015595\n",
       "18   standardize__CWalks   -184.423611\n",
       "13   standardize__CAtBat   -225.406548\n",
       "6     standardize__AtBat   -270.686441"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ridge regression data frame of coefficients and their variable labels\n",
    "r_df = variable_names_df(fitted_pipeline_r, coeff_r)\n",
    "r_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b7cdf-4363-4a5a-9b6b-621360cf12c3",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35d08fcc-36ce-45f9-84ff-663815ecfe58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating ridge regression pipeline\n",
    "\n",
    "pipeline_lasso = model(regression_label = \"lasso_reg\", type_of_regression = Lasso())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41e8c404-224a-44ab-a4f7-c62735c5c368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambdas_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "lambdas = {'lasso_reg__alpha': lambdas_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv_l = GridSearchCV(pipeline_lasso, lambdas, cv = 5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6bc0227-c389-4911-b699-5a1d59213d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.984e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.096e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.537e+06, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.594e+06, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.059e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.591e+06, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.471e+05, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.066e+06, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.923e+04, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+05, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+05, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e+04, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.282e+05, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.815e+03, tolerance: 4.281e+03\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso_reg__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>119761.587407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>120682.252637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>120964.764686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>120994.179815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>121828.141333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_lasso_reg__alpha  mean_test_score\n",
       "3                      1    119761.587407\n",
       "2                    0.1    120682.252637\n",
       "1                   0.01    120964.764686\n",
       "0                  0.001    120994.179815\n",
       "4                     10    121828.141333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting gridsearchcv to entire dataset\n",
    "gscv_fitted_l = gscv_l.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "lasso_df = pd.DataFrame(gscv_fitted_l.cv_results_)\n",
    "lasso_df = lasso_df[[\"param_lasso_reg__alpha\", \"mean_test_score\"]] #get the columns i want\n",
    "lasso_df[\"mean_test_score\"] = lasso_df[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "lasso_df.sort_values(by = \"mean_test_score\", ascending = True) #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff6d5ed-2d0e-49ea-9ce9-72274b344d7e",
   "metadata": {},
   "source": [
    "### Model with lambda = 1 is the best model, since it has the lowest MSE. The MSE estimated is 119761.587407."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7e00589-029e-4fb2-b897-c6b16c31742c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.58260721e+01,  9.97464147e-14,  1.14412951e+02, -2.07892950e-11,\n",
       "        0.00000000e+00, -0.00000000e+00, -2.82370957e+02,  3.04359509e+02,\n",
       "        1.11270220e+01, -2.49665071e+01, -0.00000000e+00,  1.20695275e+02,\n",
       "       -3.49481481e+01, -1.62639794e+02,  0.00000000e+00,  1.42259932e+01,\n",
       "        3.75565519e+02,  1.92610892e+02, -1.89644642e+02,  7.87603658e+01,\n",
       "        4.19966795e+01, -1.84793784e+01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit lasso regression model on entire data set using this lambda = 1\n",
    "pipeline_l_1 = model(regression_label = \"lasso_reg\", type_of_regression = Lasso(alpha = 1))\n",
    "fitted_pipeline_l = pipeline_l_1.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_l = fitted_pipeline_l.named_steps[\"lasso_reg\"].coef_\n",
    "coeff_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e878b250-cf98-42b6-9bc6-2d71923139ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>3.755655e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>3.043595e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>1.926109e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>1.206953e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dummify__Division_E</td>\n",
       "      <td>1.144130e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>standardize__PutOuts</td>\n",
       "      <td>7.876037e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>standardize__Assists</td>\n",
       "      <td>4.199668e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>standardize__CHmRun</td>\n",
       "      <td>1.422599e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>standardize__HmRun</td>\n",
       "      <td>1.112702e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dummify__League_N</td>\n",
       "      <td>9.974641e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dummify__NewLeague_A</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dummify__NewLeague_N</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>standardize__RBI</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummify__Division_W</td>\n",
       "      <td>-2.078929e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>standardize__Errors</td>\n",
       "      <td>-1.847938e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>standardize__Runs</td>\n",
       "      <td>-2.496651e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>standardize__Years</td>\n",
       "      <td>-3.494815e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummify__League_A</td>\n",
       "      <td>-3.582607e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>standardize__CAtBat</td>\n",
       "      <td>-1.626398e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>standardize__CWalks</td>\n",
       "      <td>-1.896446e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>standardize__AtBat</td>\n",
       "      <td>-2.823710e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           variable_name  coefficients\n",
       "16    standardize__CRuns  3.755655e+02\n",
       "7      standardize__Hits  3.043595e+02\n",
       "17     standardize__CRBI  1.926109e+02\n",
       "11    standardize__Walks  1.206953e+02\n",
       "2    dummify__Division_E  1.144130e+02\n",
       "19  standardize__PutOuts  7.876037e+01\n",
       "20  standardize__Assists  4.199668e+01\n",
       "15   standardize__CHmRun  1.422599e+01\n",
       "8     standardize__HmRun  1.112702e+01\n",
       "1      dummify__League_N  9.974641e-14\n",
       "4   dummify__NewLeague_A  0.000000e+00\n",
       "5   dummify__NewLeague_N -0.000000e+00\n",
       "10      standardize__RBI -0.000000e+00\n",
       "14    standardize__CHits  0.000000e+00\n",
       "3    dummify__Division_W -2.078929e-11\n",
       "21   standardize__Errors -1.847938e+01\n",
       "9      standardize__Runs -2.496651e+01\n",
       "12    standardize__Years -3.494815e+01\n",
       "0      dummify__League_A -3.582607e+01\n",
       "13   standardize__CAtBat -1.626398e+02\n",
       "18   standardize__CWalks -1.896446e+02\n",
       "6     standardize__AtBat -2.823710e+02"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lasso regression data frame of coefficients and their variable labels\n",
    "l_df = variable_names_df(fitted_pipeline_l, coeff_l)\n",
    "l_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ee22e-0bdf-4566-a48b-0bb5d1e4e4ff",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "515aff43-87ae-4883-8ffe-b5707f2c0358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_en = model(regression_label = \"elastic_net\", type_of_regression = ElasticNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "597007f3-2f07-4460-99bc-0ffc127413a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+07, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.228e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+07, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.455e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.786e+06, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+07, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.218e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+07, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.446e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.778e+06, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+07, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.137e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+07, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.359e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.710e+06, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+07, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.984e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+07, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.096e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.537e+06, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+04, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.205e+04, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+05, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.479e+05, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.594e+06, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.059e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.591e+06, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.471e+05, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.066e+06, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.923e+04, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+05, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+05, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e+04, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.282e+05, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.815e+03, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 125.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'l1_ratio' parameter of ElasticNet must be a float in the range [0.0, 1.0]. Got 10 instead.\n",
      "\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [-119911.91365751 -119917.20264842 -119972.79781023 -120994.17981481\n",
      "              nan -118958.09878962 -118959.30308411 -118973.7894773\n",
      " -120964.76468618              nan -119804.89171439 -119799.62805192\n",
      " -119745.30106465 -120682.25263745              nan -122027.0335249\n",
      " -122002.52898175 -121760.92284052 -119761.58740741              nan\n",
      " -150012.48781423 -149815.94530466 -147771.74467156 -121828.14133339\n",
      "              nan]\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+05, tolerance: 5.332e+03\n"
     ]
    }
   ],
   "source": [
    "#lambda AND alpha lists\n",
    "\n",
    "lambdas_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "alpha_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "param = {'elastic_net__alpha': lambdas_list,\n",
    "          \"elastic_net__l1_ratio\" : alpha_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv_en = GridSearchCV(pipeline_en, param, cv = 5, scoring='neg_mean_squared_error')\n",
    "gscv_fitted_en = gscv_en.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac879add-6674-48c3-941c-e8992abf8de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_elastic_net__alpha</th>\n",
       "      <th>param_elastic_net__l1_ratio</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>118958.098790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>118959.303084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>118973.789477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>119745.301065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119761.587407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_elastic_net__alpha param_elastic_net__l1_ratio  mean_test_score\n",
       "5                      0.01                       0.001    118958.098790\n",
       "6                      0.01                        0.01    118959.303084\n",
       "7                      0.01                         0.1    118973.789477\n",
       "12                      0.1                         0.1    119745.301065\n",
       "18                        1                           1    119761.587407"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe for mse values and lambda values\n",
    "en_df = pd.DataFrame(gscv_fitted_en.cv_results_)\n",
    "\n",
    "en_df = en_df[[\"param_elastic_net__alpha\", \"param_elastic_net__l1_ratio\", \"mean_test_score\"]] #get the columns i want\n",
    "en_df[\"mean_test_score\"] = en_df[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "en_df.sort_values(by = \"mean_test_score\", ascending = True).head() #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8653d745-e721-49fe-9f9a-76ca9248e68f",
   "metadata": {},
   "source": [
    "### Best model with elastic net is when the lambda value is 0.01 and the alpha value is 0.001. It has the lowest MSE: 118958.098790."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aeaadb5-d0e6-40b1-945e-b983e8b3026f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+05, tolerance: 5.332e+03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -29.05785518,   29.05785595,   60.81261747,  -60.81261663,\n",
       "         12.39660091,  -12.39660087, -233.34388128,  249.99503586,\n",
       "          5.38062416,   -6.9773345 ,    1.89754395,  111.88494513,\n",
       "        -49.50593632, -122.2410746 ,  123.66236751,   55.63591034,\n",
       "        226.92489624,  122.96379112, -156.53102835,   77.97700305,\n",
       "         41.46248505,  -24.75284625])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_en = model(regression_label = \"elastic_net\", type_of_regression = ElasticNet(alpha = 0.01, l1_ratio = 0.001))\n",
    "fitted_pipeline_en = pipeline_en.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_en = fitted_pipeline_en.named_steps[\"elastic_net\"].coef_\n",
    "coeff_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b5dff80-9fd0-46a9-9059-5ad92f62d87e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>249.995036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>226.924896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>123.662368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>122.963791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>111.884945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>standardize__PutOuts</td>\n",
       "      <td>77.977003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dummify__Division_E</td>\n",
       "      <td>60.812617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>standardize__CHmRun</td>\n",
       "      <td>55.635910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>standardize__Assists</td>\n",
       "      <td>41.462485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dummify__League_N</td>\n",
       "      <td>29.057856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dummify__NewLeague_A</td>\n",
       "      <td>12.396601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>standardize__HmRun</td>\n",
       "      <td>5.380624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>standardize__RBI</td>\n",
       "      <td>1.897544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>standardize__Runs</td>\n",
       "      <td>-6.977334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dummify__NewLeague_N</td>\n",
       "      <td>-12.396601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>standardize__Errors</td>\n",
       "      <td>-24.752846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummify__League_A</td>\n",
       "      <td>-29.057855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>standardize__Years</td>\n",
       "      <td>-49.505936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummify__Division_W</td>\n",
       "      <td>-60.812617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>standardize__CAtBat</td>\n",
       "      <td>-122.241075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>standardize__CWalks</td>\n",
       "      <td>-156.531028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>standardize__AtBat</td>\n",
       "      <td>-233.343881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           variable_name  coefficients\n",
       "7      standardize__Hits    249.995036\n",
       "16    standardize__CRuns    226.924896\n",
       "14    standardize__CHits    123.662368\n",
       "17     standardize__CRBI    122.963791\n",
       "11    standardize__Walks    111.884945\n",
       "19  standardize__PutOuts     77.977003\n",
       "2    dummify__Division_E     60.812617\n",
       "15   standardize__CHmRun     55.635910\n",
       "20  standardize__Assists     41.462485\n",
       "1      dummify__League_N     29.057856\n",
       "4   dummify__NewLeague_A     12.396601\n",
       "8     standardize__HmRun      5.380624\n",
       "10      standardize__RBI      1.897544\n",
       "9      standardize__Runs     -6.977334\n",
       "5   dummify__NewLeague_N    -12.396601\n",
       "21   standardize__Errors    -24.752846\n",
       "0      dummify__League_A    -29.057855\n",
       "12    standardize__Years    -49.505936\n",
       "3    dummify__Division_W    -60.812617\n",
       "13   standardize__CAtBat   -122.241075\n",
       "18   standardize__CWalks   -156.531028\n",
       "6     standardize__AtBat   -233.343881"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elastic net regression data frame of coefficients and their variable labels\n",
    "en_df = variable_names_df(fitted_pipeline_en, coeff_en)\n",
    "en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e7e7314-6b58-4362-b9a2-9eb3077a6764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients_lr</th>\n",
       "      <th>coefficients_ridge</th>\n",
       "      <th>coefficients_lasso</th>\n",
       "      <th>coefficients_elastic_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>480.747135</td>\n",
       "      <td>320.412169</td>\n",
       "      <td>3.755655e+02</td>\n",
       "      <td>226.924896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>337.830479</td>\n",
       "      <td>296.645050</td>\n",
       "      <td>3.043595e+02</td>\n",
       "      <td>249.995036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>260.689886</td>\n",
       "      <td>160.386784</td>\n",
       "      <td>1.926109e+02</td>\n",
       "      <td>122.963791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>135.073897</td>\n",
       "      <td>124.407173</td>\n",
       "      <td>1.206953e+02</td>\n",
       "      <td>111.884945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>86.687617</td>\n",
       "      <td>126.659607</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>123.662368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>standardize__PutOuts</td>\n",
       "      <td>78.761296</td>\n",
       "      <td>78.623656</td>\n",
       "      <td>7.876037e+01</td>\n",
       "      <td>77.977003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dummify__Division_E</td>\n",
       "      <td>58.424623</td>\n",
       "      <td>60.015595</td>\n",
       "      <td>1.144130e+02</td>\n",
       "      <td>60.812617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>standardize__Assists</td>\n",
       "      <td>53.732490</td>\n",
       "      <td>47.462597</td>\n",
       "      <td>4.199668e+01</td>\n",
       "      <td>41.462485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>standardize__HmRun</td>\n",
       "      <td>37.853837</td>\n",
       "      <td>18.100592</td>\n",
       "      <td>1.112702e+01</td>\n",
       "      <td>5.380624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dummify__League_N</td>\n",
       "      <td>31.299712</td>\n",
       "      <td>30.438855</td>\n",
       "      <td>9.974641e-14</td>\n",
       "      <td>29.057856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dummify__NewLeague_A</td>\n",
       "      <td>12.381163</td>\n",
       "      <td>13.111282</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>12.396601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dummify__NewLeague_N</td>\n",
       "      <td>-12.381163</td>\n",
       "      <td>-13.111282</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-12.396601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>standardize__CHmRun</td>\n",
       "      <td>-14.181723</td>\n",
       "      <td>39.070924</td>\n",
       "      <td>1.422599e+01</td>\n",
       "      <td>55.635910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>standardize__Years</td>\n",
       "      <td>-16.693359</td>\n",
       "      <td>-38.667748</td>\n",
       "      <td>-3.494815e+01</td>\n",
       "      <td>-49.505936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardize__Errors</td>\n",
       "      <td>-22.160862</td>\n",
       "      <td>-23.724190</td>\n",
       "      <td>-1.847938e+01</td>\n",
       "      <td>-24.752846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>standardize__RBI</td>\n",
       "      <td>-26.994984</td>\n",
       "      <td>-9.113295</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>1.897544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dummify__League_A</td>\n",
       "      <td>-31.299712</td>\n",
       "      <td>-30.438855</td>\n",
       "      <td>-3.582607e+01</td>\n",
       "      <td>-29.057855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dummify__Division_W</td>\n",
       "      <td>-58.424623</td>\n",
       "      <td>-60.015595</td>\n",
       "      <td>-2.078929e-11</td>\n",
       "      <td>-60.812617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>standardize__Runs</td>\n",
       "      <td>-60.572479</td>\n",
       "      <td>-29.339406</td>\n",
       "      <td>-2.496651e+01</td>\n",
       "      <td>-6.977334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>standardize__CWalks</td>\n",
       "      <td>-213.892259</td>\n",
       "      <td>-184.423611</td>\n",
       "      <td>-1.896446e+02</td>\n",
       "      <td>-156.531028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>standardize__AtBat</td>\n",
       "      <td>-291.094556</td>\n",
       "      <td>-270.686441</td>\n",
       "      <td>-2.823710e+02</td>\n",
       "      <td>-233.343881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>standardize__CAtBat</td>\n",
       "      <td>-391.038655</td>\n",
       "      <td>-225.406548</td>\n",
       "      <td>-1.626398e+02</td>\n",
       "      <td>-122.241075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           variable_name  coefficients_lr  coefficients_ridge  \\\n",
       "0     standardize__CRuns       480.747135          320.412169   \n",
       "1      standardize__Hits       337.830479          296.645050   \n",
       "2      standardize__CRBI       260.689886          160.386784   \n",
       "3     standardize__Walks       135.073897          124.407173   \n",
       "4     standardize__CHits        86.687617          126.659607   \n",
       "5   standardize__PutOuts        78.761296           78.623656   \n",
       "6    dummify__Division_E        58.424623           60.015595   \n",
       "7   standardize__Assists        53.732490           47.462597   \n",
       "8     standardize__HmRun        37.853837           18.100592   \n",
       "9      dummify__League_N        31.299712           30.438855   \n",
       "10  dummify__NewLeague_A        12.381163           13.111282   \n",
       "11  dummify__NewLeague_N       -12.381163          -13.111282   \n",
       "12   standardize__CHmRun       -14.181723           39.070924   \n",
       "13    standardize__Years       -16.693359          -38.667748   \n",
       "14   standardize__Errors       -22.160862          -23.724190   \n",
       "15      standardize__RBI       -26.994984           -9.113295   \n",
       "16     dummify__League_A       -31.299712          -30.438855   \n",
       "17   dummify__Division_W       -58.424623          -60.015595   \n",
       "18     standardize__Runs       -60.572479          -29.339406   \n",
       "19   standardize__CWalks      -213.892259         -184.423611   \n",
       "20    standardize__AtBat      -291.094556         -270.686441   \n",
       "21   standardize__CAtBat      -391.038655         -225.406548   \n",
       "\n",
       "    coefficients_lasso  coefficients_elastic_net  \n",
       "0         3.755655e+02                226.924896  \n",
       "1         3.043595e+02                249.995036  \n",
       "2         1.926109e+02                122.963791  \n",
       "3         1.206953e+02                111.884945  \n",
       "4         0.000000e+00                123.662368  \n",
       "5         7.876037e+01                 77.977003  \n",
       "6         1.144130e+02                 60.812617  \n",
       "7         4.199668e+01                 41.462485  \n",
       "8         1.112702e+01                  5.380624  \n",
       "9         9.974641e-14                 29.057856  \n",
       "10        0.000000e+00                 12.396601  \n",
       "11       -0.000000e+00                -12.396601  \n",
       "12        1.422599e+01                 55.635910  \n",
       "13       -3.494815e+01                -49.505936  \n",
       "14       -1.847938e+01                -24.752846  \n",
       "15       -0.000000e+00                  1.897544  \n",
       "16       -3.582607e+01                -29.057855  \n",
       "17       -2.078929e-11                -60.812617  \n",
       "18       -2.496651e+01                 -6.977334  \n",
       "19       -1.896446e+02               -156.531028  \n",
       "20       -2.823710e+02               -233.343881  \n",
       "21       -1.626398e+02               -122.241075  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#left join all dataframes from each regression to show coefficients\n",
    "coeff_df = pd.merge(lr_df, r_df, on = \"variable_name\", how = \"left\", suffixes=(\"\", \"_ridge\"))\n",
    "coeff_df = pd.merge(coeff_df, l_df, on = \"variable_name\", how = \"left\", suffixes = (\"\", \"_lasso\"))\n",
    "coeff_df = pd.merge(coeff_df, en_df, on = \"variable_name\", how = \"left\", suffixes = (\"\", \"_elastic_net\"))\n",
    "coeff_df.rename(columns={\"coefficients\": \"coefficients_lr\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1643d036-0f71-4c70-ba3f-46d701c5e6ed",
   "metadata": {},
   "source": [
    "# Part 2: Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9e6f7-338a-438c-b59d-da4114717102",
   "metadata": {},
   "source": [
    "### The elastic net regression has the lowest MSE, so this is the preferred model. In that model, the top 5 numberical variables are Hits, CRuns, CHits, CRBI, and Walks. The top 1 numerical variable is Hits. The top categorical variable is Division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa3ac107-ed2a-40f9-973c-6a207e31ce10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create function with specified numberical variables\n",
    "def top_num_model(list_col, regression_label, type_of_regression):\n",
    "    \n",
    "    \"\"\"\n",
    "    transforms columns and outputs a pipeline of the desired kind of regression model with numerical variables\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    list_col: array\n",
    "    An array of column names to be transfomed in the column transformer\n",
    "    \n",
    "    regression_label : str\n",
    "    A string represeting the label of the modeling type\n",
    "    \n",
    "    type_of_regression: sklearn function\n",
    "    A specific function for the modeling type \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arrays \n",
    "    returns the pipeline of the specified type of model\n",
    "    \"\"\"\n",
    "    \n",
    "    ct = ColumnTransformer([\n",
    "    # (\"dummify\", OneHotEncoder(sparse_output = False, handle_unknown = \"ignore\"), [\"Division\"]), \n",
    "    (\"standardize\", StandardScaler(), list_col)], remainder = \"drop\") #drop everything else\n",
    "    \n",
    "    lr_pipeline = Pipeline(\n",
    "      [(\"preprocessing\", ct),\n",
    "      (regression_label, type_of_regression)]\n",
    "    ).set_output(transform = \"pandas\")\n",
    "    \n",
    "    return lr_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d09235-b81f-484b-8d98-fa375301a4ef",
   "metadata": {},
   "source": [
    "## Model using the one best numeric variable: Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1cfe6-0234-4726-8816-ceb45ca7b379",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6838769e-22eb-44a3-acf9-b73874e97536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run linear regression\n",
    "pipe1 = top_num_model([\"Hits\"], \"linear_reg\", LinearRegression())\n",
    "fitted_pipe1 = pipe1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ebd7af9-fded-4fe5-a0d0-86bfbe98559a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([197.51778566])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefficients for linear model\n",
    "coeff1 = fitted_pipe1.named_steps[\"linear_reg\"].coef_\n",
    "coeff1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6057454-9200-47a4-ace3-6be1ecc3b582",
   "metadata": {},
   "source": [
    "### The coefficient value for Hits in a linear model is 197.52."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1fefa07-7ebb-4377-ac30-2c7068236243",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173088.97286444032"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross validation mse for linear model\n",
    "cross_val_scores1 = cross_val_score(pipe1, X, y, cv = 5, scoring = 'neg_mean_squared_error')\n",
    "-cross_val_scores1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbc3d2-6ab2-49f6-a0d2-d5165b53dd4c",
   "metadata": {},
   "source": [
    "### The mean MSE for a linear regression with just one numerical variable Hits is 173088.97."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cecb6fa-c4a4-4d42-8f77-0ebc0085b71c",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da188560-5e78-46ff-810e-116d7ae8133b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_ridge_reg__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>172755.975523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>173046.230311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>173084.595954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>173088.534138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>173088.928981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_ridge_reg__alpha  mean_test_score\n",
       "4                     10    172755.975523\n",
       "3                      1    173046.230311\n",
       "2                    0.1    173084.595954\n",
       "1                   0.01    173088.534138\n",
       "0                  0.001    173088.928981"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1_r = top_num_model([\"Hits\"], \"ridge_reg\", Ridge())\n",
    "\n",
    "#creating dictionary with different lambda values for tuning\n",
    "lambdas_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "lambdas = {'ridge_reg__alpha': lambdas_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv1r = GridSearchCV(pipe1_r, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "#fitting gridsearchcv to entire dataset\n",
    "gscv_fitted1r = gscv1r.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "ridge_df1 = pd.DataFrame(gscv_fitted1r.cv_results_)\n",
    "ridge_df1\n",
    "ridge_df1 = ridge_df1[[\"param_ridge_reg__alpha\", \"mean_test_score\"]] #get the columns i want\n",
    "ridge_df1[\"mean_test_score\"] = ridge_df1[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "ridge_df1.sort_values(by = \"mean_test_score\", ascending = True) #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2af6b-a7b8-4b30-831c-68f90fc1a55c",
   "metadata": {},
   "source": [
    "### Model with lambda = 10 is the best model; it has the lowest MSE: 143658.517369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab3da61f-157f-4f34-a2cd-7e28a4e92bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190.28270194])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit ridge regression model on entire data set using this lambda = 1\n",
    "pipe_r1 = top_num_model([\"Hits\"], regression_label = \"ridge_reg\", type_of_regression = Ridge(alpha = 10))\n",
    "fitted_pipe_r1 = pipe_r1.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_r1 = fitted_pipe_r1.named_steps[\"ridge_reg\"].coef_\n",
    "coeff_r1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932491f3-7f7a-4bca-a524-7c95cf81fe0b",
   "metadata": {},
   "source": [
    "### The coefficient value for Hits is 190.28270194 in a ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a12e45-4c09-47e8-9300-8615954d1053",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "018f7239-4ea0-4dec-bba9-4ad79d096cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso_reg__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>173061.634500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>173076.934306</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>173087.675961</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>173088.842244</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>173088.959793</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_lasso_reg__alpha  mean_test_score  rank_test_score\n",
       "4                     10    173061.634500                1\n",
       "3                      1    173076.934306                2\n",
       "2                    0.1    173087.675961                3\n",
       "1                   0.01    173088.842244                4\n",
       "0                  0.001    173088.959793                5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run lasso regression\n",
    "pipe1_l = top_num_model([\"Hits\"], \"lasso_reg\", Lasso())\n",
    "\n",
    "#create dictionary of lambda values\n",
    "# lambdas_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "lambdas = {'lasso_reg__alpha': lambdas_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv_l1 = GridSearchCV(pipe1_l, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "#fitting gridsearchcv to entire dataset\n",
    "gscv_fitted_l1 = gscv_l1.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "lasso_df1 = pd.DataFrame(gscv_fitted_l1.cv_results_)\n",
    "lasso_df1\n",
    "lasso_df1 = lasso_df1[[\"param_lasso_reg__alpha\", \"mean_test_score\", \"rank_test_score\"]] #get the columns i want\n",
    "lasso_df1[\"mean_test_score\"] = lasso_df1[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "lasso_df1.sort_values(by = \"rank_test_score\", ascending = True) #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66245eaf-10f4-4760-b811-d6d0701df1df",
   "metadata": {},
   "source": [
    "### The best model is when lambda = 10. The MSE is 173061.634500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "650539d7-5bc9-4209-aedd-6689d248f2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([187.51778566])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit lasso regression model on entire data set using this lambda = 1\n",
    "pipeline_l1 = top_num_model([\"Hits\"], regression_label = \"lasso_reg\", type_of_regression = Lasso(alpha = 10))\n",
    "fitted_pipeline_l1 = pipeline_l1.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_l1 = fitted_pipeline_l1.named_steps[\"lasso_reg\"].coef_\n",
    "coeff_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1151324-d89a-40e2-9148-bc2b6595d199",
   "metadata": {},
   "source": [
    "### The coefficient for Hits is 187.51778566."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7ba9c-7296-4fff-9459-79bd9d1aee0c",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f18c7f5-de78-4b9a-a4bc-89ed8c1750ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 125.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'l1_ratio' parameter of ElasticNet must be a float in the range [0.0, 1.0]. Got 10 instead.\n",
      "\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [-173079.69238456 -173079.7754236  -173080.60626447 -173088.95979306\n",
      "              nan -173000.67987087 -173001.43045891 -173008.97929702\n",
      " -173088.84224366              nan -172586.22247528 -172587.55335213\n",
      " -172603.55430167 -173087.67596136              nan -178885.26481806\n",
      " -178812.73652523 -178075.14841194 -173076.93430582              nan\n",
      " -199219.40411557 -199172.2099693  -198656.33390788 -173061.63450003\n",
      "              nan]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_elastic_net__alpha</th>\n",
       "      <th>param_elastic_net__l1_ratio</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>172586.222475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>172587.553352</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>172603.554302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>173000.679871</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>173001.430459</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_elastic_net__alpha param_elastic_net__l1_ratio  mean_test_score  \\\n",
       "10                      0.1                       0.001    172586.222475   \n",
       "11                      0.1                        0.01    172587.553352   \n",
       "12                      0.1                         0.1    172603.554302   \n",
       "5                      0.01                       0.001    173000.679871   \n",
       "6                      0.01                        0.01    173001.430459   \n",
       "\n",
       "    rank_test_score  \n",
       "10                1  \n",
       "11                2  \n",
       "12                3  \n",
       "5                 4  \n",
       "6                 5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run regression\n",
    "pipeline_en1 = top_num_model([\"Hits\"], regression_label = \"elastic_net\", type_of_regression = ElasticNet())\n",
    "\n",
    "#lambda AND alpha lists\n",
    "\n",
    "lambdas_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "alpha_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "param = {'elastic_net__alpha': lambdas_list,\n",
    "          \"elastic_net__l1_ratio\" : alpha_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv_en1 = GridSearchCV(pipeline_en1, param, cv = 5, scoring='neg_mean_squared_error')\n",
    "gscv_fitted_en1 = gscv_en1.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "en_df1 = pd.DataFrame(gscv_fitted_en1.cv_results_)\n",
    "\n",
    "en_df1 = en_df1[[\"param_elastic_net__alpha\", \"param_elastic_net__l1_ratio\", \"mean_test_score\", \"rank_test_score\"]] \n",
    "en_df1[\"mean_test_score\"] = en_df1[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "en_df1.sort_values(by = \"rank_test_score\", ascending = True).head() #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4d42f-e074-4e8e-af7b-2aaa721fd082",
   "metadata": {},
   "source": [
    "### The model where lambda = 0.1 and alpha = 0.001 is the best model, since it has the lowest MSE. The MSE is 172586.222475."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a904d23-f1df-41f3-bc07-bc890b6561e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.57785768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit pipeline with respective lambda and alpha values\n",
    "pipeline_en1 = top_num_model([\"Hits\"], regression_label = \"elastic_net\", type_of_regression = ElasticNet(alpha = 0.1, l1_ratio = 0.001))\n",
    "fitted_pipeline_en1 = pipeline_en1.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_en1 = fitted_pipeline_en1.named_steps[\"elastic_net\"].coef_\n",
    "coeff_en1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a58b79-5751-4cf5-8451-986202a33ecc",
   "metadata": {},
   "source": [
    "### The coefficient for this model is 179.578."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468eec4-f9b4-44b1-bd6b-8083679b9d7d",
   "metadata": {},
   "source": [
    "## Model using the 5 best variables: Hits, CRuns, CHits, CRBI, and Walks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0344fb9d-0182-4224-84b4-af940a96bbc5",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df6128a3-ce99-4461-b3a7-d5e8a8f996b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run linear regression\n",
    "pipe5 = top_num_model([\"Hits\", \"CRuns\", \"CHits\", \"CRBI\", \"Walks\"], \"linear_reg\", LinearRegression())\n",
    "fitted_pipe5 = pipe5.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "443435ee-6419-47d3-9f5c-c7ff31bc9afe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112.19143792,  91.95132612, -41.23766725, 162.87411679,\n",
       "        63.58366543])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefficients for linear model\n",
    "coeff5 = fitted_pipe5.named_steps[\"linear_reg\"].coef_\n",
    "coeff5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bc0297b-1c1f-487b-a4e9-3c614290c79e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>162.874117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>112.191438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>91.951326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>63.583665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>-41.237667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        variable_name  coefficients\n",
       "3   standardize__CRBI    162.874117\n",
       "0   standardize__Hits    112.191438\n",
       "1  standardize__CRuns     91.951326\n",
       "4  standardize__Walks     63.583665\n",
       "2  standardize__CHits    -41.237667"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear regression data frame of coefficients and their variable labels\n",
    "lr_df5 = variable_names_df(fitted_pipe5, coeff5)\n",
    "lr_df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "466aa80d-1c0d-43cc-ad2d-c865926b5cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126047.77085146765"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE values using cross validation\n",
    "\n",
    "cross_val_scores5 = cross_val_score(pipe5, X, y, cv = 5, scoring = 'neg_mean_squared_error')\n",
    "-cross_val_scores5.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d426f-5c31-408b-af5b-3c7c74f62009",
   "metadata": {},
   "source": [
    "### The MSE for this linear regression model with the top 5 numerical variables is 126047.77."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a14b94-76ab-4f7f-a581-160bbd646cda",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d34d866d-46f7-459a-b5e1-3346b4ba1a29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_ridge_reg__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>123172.832275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>125269.250471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>125949.562233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>126037.669848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>126046.757841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_ridge_reg__alpha  mean_test_score\n",
       "4                     10    123172.832275\n",
       "3                      1    125269.250471\n",
       "2                    0.1    125949.562233\n",
       "1                   0.01    126037.669848\n",
       "0                  0.001    126046.757841"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run ridge regression\n",
    "pipe5r = top_num_model([\"Hits\", \"CRuns\", \"CHits\", \"CRBI\", \"Walks\"], \"ridge_reg\", Ridge())\n",
    "fitted_pipe5r = pipe5r.fit(X, y)\n",
    "\n",
    "lambdas = {'ridge_reg__alpha': lambdas_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv5 = GridSearchCV(pipe5r, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "#fitting gridsearchcv to entire dataset\n",
    "gscv_fitted5 = gscv5.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "ridge_df5 = pd.DataFrame(gscv_fitted5.cv_results_)\n",
    "ridge_df5\n",
    "ridge_df5 = ridge_df5[[\"param_ridge_reg__alpha\", \"mean_test_score\"]] #get the columns i want\n",
    "ridge_df5[\"mean_test_score\"] = ridge_df5[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "ridge_df5.sort_values(by = \"mean_test_score\", ascending = True) #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0da8c-b3ab-4fe8-9284-f1c2770c54e0",
   "metadata": {},
   "source": [
    "### The model with the lambda = 10 is the best model. The MSE is 123172.832275."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95fb78be-9e6b-4945-ba86-75ce32c0b17c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>126.472957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>104.861189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>69.846563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>57.286936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>26.383317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        variable_name  coefficients\n",
       "3   standardize__CRBI    126.472957\n",
       "0   standardize__Hits    104.861189\n",
       "4  standardize__Walks     69.846563\n",
       "1  standardize__CRuns     57.286936\n",
       "2  standardize__CHits     26.383317"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit ridge regression model on entire data set using this lambda = 1\n",
    "pipe_r5 = top_num_model([\"Hits\", \"CRuns\", \"CHits\", \"CRBI\", \"Walks\"], regression_label = \"ridge_reg\", type_of_regression = Ridge(alpha = 10))\n",
    "fitted_pipe_r5 = pipe_r5.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_r5 = fitted_pipe_r5.named_steps[\"ridge_reg\"].coef_\n",
    "coeff_r5\n",
    "\n",
    "#ridge regression data frame of coefficients and their variable labels\n",
    "r_df5 = variable_names_df(fitted_pipe_r5, coeff_r5)\n",
    "r_df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b4f68-eec6-420f-87c4-9df5b5c45169",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7688e4e6-6bdb-4003-8db0-b51a14d90d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso_reg__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>124607.221700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>125051.186707</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>125905.459601</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>126034.140880</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>126046.406095</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_lasso_reg__alpha  mean_test_score  rank_test_score\n",
       "4                     10    124607.221700                1\n",
       "3                      1    125051.186707                2\n",
       "2                    0.1    125905.459601                3\n",
       "1                   0.01    126034.140880                4\n",
       "0                  0.001    126046.406095                5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run lasso regression\n",
    "pipe5_l = top_num_model([\"Hits\", \"CRuns\", \"CHits\", \"CRBI\", \"Walks\"], \"lasso_reg\", Lasso())\n",
    "\n",
    "#create dictionary of lambda values\n",
    "# lambdas_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "lambdas = {'lasso_reg__alpha': lambdas_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv_l5 = GridSearchCV(pipe5_l, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "#fitting gridsearchcv to entire dataset\n",
    "gscv_fitted_l5 = gscv_l5.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "lasso_df5 = pd.DataFrame(gscv_fitted_l5.cv_results_)\n",
    "lasso_df5\n",
    "lasso_df5 = lasso_df5[[\"param_lasso_reg__alpha\", \"mean_test_score\", \"rank_test_score\"]] #get the columns i want\n",
    "lasso_df5[\"mean_test_score\"] = lasso_df5[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "lasso_df5.sort_values(by = \"rank_test_score\", ascending = True) #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa113c6c-b939-4923-8d00-910c844e5523",
   "metadata": {},
   "source": [
    "### The best lasso model is when the lambda value is 10. The MSE is 124607.22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "588e2a3a-7ff2-4369-8b2b-dfcbbd41fe09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>150.985603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>104.189083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>63.263074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>54.624384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        variable_name  coefficients\n",
       "3   standardize__CRBI    150.985603\n",
       "0   standardize__Hits    104.189083\n",
       "4  standardize__Walks     63.263074\n",
       "1  standardize__CRuns     54.624384\n",
       "2  standardize__CHits      0.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit lasso regression model on entire data set using this lambda = 10\n",
    "pipe_l5 = top_num_model([\"Hits\", \"CRuns\", \"CHits\", \"CRBI\", \"Walks\"], regression_label = \"lasso_reg\", type_of_regression = Lasso(alpha = 10))\n",
    "fitted_pipe_l5 = pipe_l5.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_l5 = fitted_pipe_l5.named_steps[\"lasso_reg\"].coef_\n",
    "coeff_l5\n",
    "\n",
    "#ridge regression data frame of coefficients and their variable labels\n",
    "l_df5 = variable_names_df(fitted_pipe_l5, coeff_l5)\n",
    "l_df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56058323-51b2-4b4c-a6b9-84d3b1ffdf9b",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9dc7cd7-9a00-481f-91da-908900e1f5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 125.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'l1_ratio' parameter of ElasticNet must be a float in the range [0.0, 1.0]. Got 10 instead.\n",
      "\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [-125847.75779353 -125849.43801159 -125866.34119913 -126046.40609464\n",
      "              nan -124718.90881715 -124726.6622649  -124806.74206908\n",
      " -126034.14088031              nan -122504.71256449 -122511.83611102\n",
      " -122588.55486269 -125905.45960106              nan -125496.22905759\n",
      " -125433.78035228 -124823.86597739 -125051.18670746              nan\n",
      " -169664.91872427 -169463.43266895 -167310.92009741 -124607.2216997\n",
      "              nan]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_elastic_net__alpha</th>\n",
       "      <th>param_elastic_net__l1_ratio</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>122504.712564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>122511.836111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>122588.554863</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>124607.221700</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>124718.908817</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_elastic_net__alpha param_elastic_net__l1_ratio  mean_test_score  \\\n",
       "10                      0.1                       0.001    122504.712564   \n",
       "11                      0.1                        0.01    122511.836111   \n",
       "12                      0.1                         0.1    122588.554863   \n",
       "23                       10                           1    124607.221700   \n",
       "5                      0.01                       0.001    124718.908817   \n",
       "\n",
       "    rank_test_score  \n",
       "10                1  \n",
       "11                2  \n",
       "12                3  \n",
       "23                4  \n",
       "5                 5  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run regression\n",
    "pipeline_en5 = top_num_model([\"Hits\", \"CRuns\", \"CHits\", \"CRBI\", \"Walks\"], regression_label = \"elastic_net\", type_of_regression = ElasticNet())\n",
    "\n",
    "#lambda AND alpha lists\n",
    "\n",
    "lambdas_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "alpha_list = [0.001, 0.01, 0.1, 1, 10]\n",
    "param = {'elastic_net__alpha': lambdas_list,\n",
    "          \"elastic_net__l1_ratio\" : alpha_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv_en5 = GridSearchCV(pipeline_en5, param, cv = 5, scoring='neg_mean_squared_error')\n",
    "gscv_fitted_en5 = gscv_en5.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "en_df5 = pd.DataFrame(gscv_fitted_en5.cv_results_)\n",
    "\n",
    "en_df5 = en_df5[[\"param_elastic_net__alpha\", \"param_elastic_net__l1_ratio\", \"mean_test_score\", \"rank_test_score\"]] \n",
    "en_df5[\"mean_test_score\"] = en_df5[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "en_df5.sort_values(by = \"rank_test_score\", ascending = True).head() #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da641053-7eeb-4e05-bb33-541da65733de",
   "metadata": {},
   "source": [
    "### The best model is when lambda = 0.1 and alpha = 0.001. The MSE is 122504.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "048ce94b-e567-4115-bbff-d8cfacc3ce4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>103.643104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>98.869832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>70.783903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>58.389272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>44.616915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        variable_name  coefficients\n",
       "3   standardize__CRBI    103.643104\n",
       "0   standardize__Hits     98.869832\n",
       "4  standardize__Walks     70.783903\n",
       "1  standardize__CRuns     58.389272\n",
       "2  standardize__CHits     44.616915"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit elastic net regression model on entire data set using this lambda = 0.1, alpha = 0.001.\n",
    "pipe_en5 = top_num_model([\"Hits\", \"CRuns\", \"CHits\", \"CRBI\", \"Walks\"], regression_label = \"elastic_net\", type_of_regression = ElasticNet(alpha = 0.1, l1_ratio = 0.001))\n",
    "fitted_pipe_en5 = pipe_en5.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_en5 = fitted_pipe_en5.named_steps[\"elastic_net\"].coef_\n",
    "coeff_en5\n",
    "\n",
    "#ridge regression data frame of coefficients and their variable labels\n",
    "en_df5 = variable_names_df(fitted_pipe_en5, coeff_en5)\n",
    "en_df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5650cea-2056-4560-80c8-b9ee65ccf5bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model using 5 best numeric variables and their interactions with the one best categorical variable: Division"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cda69f-7706-487d-913e-a7ddc7f49984",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f65653a6-d8e6-423d-97c4-a75bba89c8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create new function for interactions with categorical variable\n",
    "#create function with specified numberical variables\n",
    "def top_model_interact(regression_label, type_of_regression):\n",
    "    \n",
    "    \"\"\"\n",
    "    transforms columns and outputs a pipeline of the desired kind of regression model \n",
    "    with numerical variables, dummy variable, and its interactions\n",
    "  \n",
    "    Parameter\n",
    "    ---------\n",
    "    \n",
    "    regression_label : str\n",
    "    A string represeting the label of the modeling type\n",
    "    \n",
    "    type_of_regression: sklearn function\n",
    "    A specific function for the modeling type \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arrays \n",
    "    returns the pipeline of the specified type of model\n",
    "    \"\"\"\n",
    "    \n",
    "    #column preprocessing - standardizing and dummifying\n",
    "    ct = ColumnTransformer([\n",
    "    (\"dummify\", OneHotEncoder(sparse_output = False, handle_unknown = \"ignore\"), [\"Division\"]), \n",
    "    (\"standardize\", StandardScaler(), [\"Hits\", \"CRuns\", \"CHits\", \"CRBI\", \"Walks\"])], remainder = \"drop\").set_output(transform = \"pandas\") #drop everything else\n",
    "\n",
    "    #interacting variables\n",
    "    ct_interact = ColumnTransformer([\n",
    "        (\"interact\", PolynomialFeatures(interaction_only = True), [\"dummify__Division_E\", \"standardize__Hits\"]),\n",
    "        (\"interact2\", PolynomialFeatures(interaction_only = True), [\"dummify__Division_E\", \"standardize__CRuns\"]),\n",
    "        (\"interact3\", PolynomialFeatures(interaction_only = True), [\"dummify__Division_E\", \"standardize__CHits\"]),\n",
    "        (\"interact4\", PolynomialFeatures(interaction_only = True), [\"dummify__Division_E\", \"standardize__CRBI\"]),\n",
    "        (\"interact5\", PolynomialFeatures(interaction_only = True), [\"dummify__Division_E\", \"standardize__Walks\"]),\n",
    "    ]).set_output(transform = \"pandas\")\n",
    "\n",
    "    #pipeline\n",
    "    lr_pipeline_inter = Pipeline([(\"preprocessing\", ct),\n",
    "                                  (\"interacting\", ct_interact),\n",
    "                                  (regression_label, type_of_regression)]).set_output(transform = \"pandas\")\n",
    "    \n",
    "    return lr_pipeline_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0d69d29-1d90-4885-a51f-acc2d546d5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>interact4__dummify__Division_E standardize__CRBI</td>\n",
       "      <td>2.571259e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>interact3__standardize__CHits</td>\n",
       "      <td>2.445364e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>interact2__dummify__Division_E standardize__CRuns</td>\n",
       "      <td>2.081468e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interact__standardize__Hits</td>\n",
       "      <td>8.444428e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>interact4__standardize__CRBI</td>\n",
       "      <td>5.876313e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>interact5__standardize__Walks</td>\n",
       "      <td>5.058454e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>interact5__dummify__Division_E standardize__Walks</td>\n",
       "      <td>3.146199e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interact__dummify__Division_E</td>\n",
       "      <td>2.790957e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>interact4__dummify__Division_E</td>\n",
       "      <td>2.790957e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>interact5__dummify__Division_E</td>\n",
       "      <td>2.790957e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interact2__dummify__Division_E</td>\n",
       "      <td>2.790957e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>interact3__dummify__Division_E</td>\n",
       "      <td>2.790957e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interact__dummify__Division_E standardize__Hits</td>\n",
       "      <td>2.769181e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interact3__1</td>\n",
       "      <td>4.121148e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interact2__1</td>\n",
       "      <td>1.847411e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>interact5__1</td>\n",
       "      <td>1.345247e-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>interact4__1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interact__1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interact2__standardize__CRuns</td>\n",
       "      <td>-1.385723e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>interact3__dummify__Division_E standardize__CHits</td>\n",
       "      <td>-3.720902e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        variable_name  coefficients\n",
       "15   interact4__dummify__Division_E standardize__CRBI  2.571259e+02\n",
       "10                      interact3__standardize__CHits  2.445364e+02\n",
       "7   interact2__dummify__Division_E standardize__CRuns  2.081468e+02\n",
       "2                         interact__standardize__Hits  8.444428e+01\n",
       "14                       interact4__standardize__CRBI  5.876313e+01\n",
       "18                      interact5__standardize__Walks  5.058454e+01\n",
       "19  interact5__dummify__Division_E standardize__Walks  3.146199e+01\n",
       "1                       interact__dummify__Division_E  2.790957e+01\n",
       "13                     interact4__dummify__Division_E  2.790957e+01\n",
       "17                     interact5__dummify__Division_E  2.790957e+01\n",
       "5                      interact2__dummify__Division_E  2.790957e+01\n",
       "9                      interact3__dummify__Division_E  2.790957e+01\n",
       "3     interact__dummify__Division_E standardize__Hits  2.769181e+01\n",
       "8                                        interact3__1  4.121148e-13\n",
       "4                                        interact2__1  1.847411e-13\n",
       "16                                       interact5__1  1.345247e-43\n",
       "12                                       interact4__1  0.000000e+00\n",
       "0                                         interact__1  0.000000e+00\n",
       "6                       interact2__standardize__CRuns -1.385723e+02\n",
       "11  interact3__dummify__Division_E standardize__CHits -3.720902e+02"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear regression model fitting\n",
    "\n",
    "pipe_inter = top_model_interact(\"linear_reg\", LinearRegression())\n",
    "fitted_pipe_lr_inter = pipe_inter.fit(X, y)\n",
    "\n",
    "#coefficients for linear model\n",
    "coeff_lr_inter = fitted_pipe_lr_inter.named_steps[\"linear_reg\"].coef_\n",
    "coeff_lr_inter\n",
    "\n",
    "#linear regression data frame of coefficients and their variable labels\n",
    "lr_df_inter = variable_names_df(fitted_pipe_lr_inter, coeff_lr_inter)\n",
    "lr_df_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9571f3b3-44a7-45b4-87a5-a5a2e42b346a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142577.59218490883"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE values using cross validation - linear regression\n",
    "\n",
    "cross_val_scores_inter = cross_val_score(pipe_inter, X, y, cv = 5, scoring = 'neg_mean_squared_error')\n",
    "-cross_val_scores_inter.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374694a0-88ee-41af-ab19-5e82ddb577e0",
   "metadata": {},
   "source": [
    "### The MSE for linear regression with interactions is 142577.59."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68a0d9-3b28-4063-b928-78b284c627a9",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88d430c2-bc50-4bcc-8a62-a7a625bbc9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_ridge_reg__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>121756.658444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>127927.034075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>133214.734017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>134694.956750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>134875.523366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_ridge_reg__alpha  mean_test_score\n",
       "4                     10    121756.658444\n",
       "3                      1    127927.034075\n",
       "2                    0.1    133214.734017\n",
       "1                   0.01    134694.956750\n",
       "0                  0.001    134875.523366"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ridge regression model fitting\n",
    "\n",
    "pipe_inter_r = top_model_interact(\"ridge_reg\", Ridge())\n",
    "\n",
    "lambdas = {'ridge_reg__alpha': lambdas_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv_inter = GridSearchCV(pipe_inter_r, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "#fitting gridsearchcv to entire dataset\n",
    "gscv_fitted_inter = gscv_inter.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "ridge_df_inter = pd.DataFrame(gscv_fitted_inter.cv_results_)\n",
    "ridge_df_inter = ridge_df_inter[[\"param_ridge_reg__alpha\", \"mean_test_score\"]] #get the columns i want\n",
    "ridge_df_inter[\"mean_test_score\"] = ridge_df_inter[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "ridge_df_inter.sort_values(by = \"mean_test_score\", ascending = True) #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061029c-2b6c-4356-8530-b6e27190339c",
   "metadata": {},
   "source": [
    "### The model where lambda = 10 is the best, it has the lowest MSE: 121756.658444."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb26a4f4-7796-4f6f-9e53-439a08ff20f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>interact4__dummify__Division_E standardize__CRBI</td>\n",
       "      <td>107.257033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>interact4__standardize__CRBI</td>\n",
       "      <td>94.534228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interact__standardize__Hits</td>\n",
       "      <td>84.696145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>interact3__standardize__CHits</td>\n",
       "      <td>53.076194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>interact5__dummify__Division_E standardize__Walks</td>\n",
       "      <td>49.076620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>interact5__standardize__Walks</td>\n",
       "      <td>41.634097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>interact4__dummify__Division_E</td>\n",
       "      <td>26.622096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>interact5__dummify__Division_E</td>\n",
       "      <td>26.622096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>interact3__dummify__Division_E</td>\n",
       "      <td>26.622096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interact2__dummify__Division_E</td>\n",
       "      <td>26.622096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interact__dummify__Division_E</td>\n",
       "      <td>26.622096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interact2__standardize__CRuns</td>\n",
       "      <td>23.327583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interact__dummify__Division_E standardize__Hits</td>\n",
       "      <td>20.167362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>interact2__dummify__Division_E standardize__CRuns</td>\n",
       "      <td>2.772595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interact3__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>interact4__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interact2__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>interact5__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interact__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>interact3__dummify__Division_E standardize__CHits</td>\n",
       "      <td>-22.509186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        variable_name  coefficients\n",
       "15   interact4__dummify__Division_E standardize__CRBI    107.257033\n",
       "14                       interact4__standardize__CRBI     94.534228\n",
       "2                         interact__standardize__Hits     84.696145\n",
       "10                      interact3__standardize__CHits     53.076194\n",
       "19  interact5__dummify__Division_E standardize__Walks     49.076620\n",
       "18                      interact5__standardize__Walks     41.634097\n",
       "13                     interact4__dummify__Division_E     26.622096\n",
       "17                     interact5__dummify__Division_E     26.622096\n",
       "9                      interact3__dummify__Division_E     26.622096\n",
       "5                      interact2__dummify__Division_E     26.622096\n",
       "1                       interact__dummify__Division_E     26.622096\n",
       "6                       interact2__standardize__CRuns     23.327583\n",
       "3     interact__dummify__Division_E standardize__Hits     20.167362\n",
       "7   interact2__dummify__Division_E standardize__CRuns      2.772595\n",
       "8                                        interact3__1      0.000000\n",
       "12                                       interact4__1      0.000000\n",
       "4                                        interact2__1      0.000000\n",
       "16                                       interact5__1      0.000000\n",
       "0                                         interact__1      0.000000\n",
       "11  interact3__dummify__Division_E standardize__CHits    -22.509186"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit ridge regression model on entire data set using this lambda = 10\n",
    "pipe_r_inter = top_model_interact(regression_label = \"ridge_reg\", type_of_regression = Ridge(alpha = 10))\n",
    "fitted_pipe_r_inter10 = pipe_r_inter.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_r_inter = fitted_pipe_r_inter10.named_steps[\"ridge_reg\"].coef_\n",
    "coeff_r_inter\n",
    "\n",
    "#ridge regression data frame of coefficients and their variable labels\n",
    "r_df_inter = variable_names_df(fitted_pipe_r_inter10, coeff_r_inter)\n",
    "r_df_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca597e-76a5-4bed-8879-aeeec0945c2f",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36424f61-e7e0-4ad4-b339-c83d185bc124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.695e+06, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.355e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+06, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.624e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.520e+06, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e+05, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+05, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.355e+04, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+05, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e+05, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.006e+03, tolerance: 4.558e+03\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso_reg__alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>121693.612794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>129431.041060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>133865.807760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>134786.266244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>134880.666188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_lasso_reg__alpha  mean_test_score\n",
       "4                     10    121693.612794\n",
       "3                      1    129431.041060\n",
       "2                    0.1    133865.807760\n",
       "1                   0.01    134786.266244\n",
       "0                  0.001    134880.666188"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lasso regression model fitting\n",
    "\n",
    "pipe_inter_l = top_model_interact(\"lasso_reg\", Lasso())\n",
    "\n",
    "lambdas = {'lasso_reg__alpha': lambdas_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv_inter_l = GridSearchCV(pipe_inter_l, lambdas, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "#fitting gridsearchcv to entire dataset\n",
    "gscv_fitted_inter_l = gscv_inter_l.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "lasso_df_inter = pd.DataFrame(gscv_fitted_inter_l.cv_results_)\n",
    "lasso_df_inter = lasso_df_inter[[\"param_lasso_reg__alpha\", \"mean_test_score\"]] #get the columns i want\n",
    "lasso_df_inter[\"mean_test_score\"] = lasso_df_inter[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "lasso_df_inter.sort_values(by = \"mean_test_score\", ascending = True) #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e552e1-78d3-45c6-914c-72432634e425",
   "metadata": {},
   "source": [
    "### Model with lambda = 10 is the best. The MSE is 121693.612794."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1bd9d347-fa98-4be4-aace-a94266c1fb08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>interact4__standardize__CRBI</td>\n",
       "      <td>123.275707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interact__standardize__Hits</td>\n",
       "      <td>94.659250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>interact4__dummify__Division_E standardize__CRBI</td>\n",
       "      <td>81.889313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interact__dummify__Division_E</td>\n",
       "      <td>62.216747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>interact5__dummify__Division_E standardize__Walks</td>\n",
       "      <td>50.010888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>interact3__standardize__CHits</td>\n",
       "      <td>44.012861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>interact5__standardize__Walks</td>\n",
       "      <td>36.938170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>interact3__dummify__Division_E</td>\n",
       "      <td>19.280822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interact2__dummify__Division_E</td>\n",
       "      <td>17.694400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interact2__standardize__CRuns</td>\n",
       "      <td>1.514646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>interact2__dummify__Division_E standardize__CRuns</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interact3__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>interact3__dummify__Division_E standardize__CHits</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>interact4__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>interact4__dummify__Division_E</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interact2__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interact__dummify__Division_E standardize__Hits</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>interact5__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>interact5__dummify__Division_E</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interact__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        variable_name  coefficients\n",
       "14                       interact4__standardize__CRBI    123.275707\n",
       "2                         interact__standardize__Hits     94.659250\n",
       "15   interact4__dummify__Division_E standardize__CRBI     81.889313\n",
       "1                       interact__dummify__Division_E     62.216747\n",
       "19  interact5__dummify__Division_E standardize__Walks     50.010888\n",
       "10                      interact3__standardize__CHits     44.012861\n",
       "18                      interact5__standardize__Walks     36.938170\n",
       "9                      interact3__dummify__Division_E     19.280822\n",
       "5                      interact2__dummify__Division_E     17.694400\n",
       "6                       interact2__standardize__CRuns      1.514646\n",
       "7   interact2__dummify__Division_E standardize__CRuns      0.000000\n",
       "8                                        interact3__1      0.000000\n",
       "11  interact3__dummify__Division_E standardize__CHits      0.000000\n",
       "12                                       interact4__1      0.000000\n",
       "13                     interact4__dummify__Division_E      0.000000\n",
       "4                                        interact2__1      0.000000\n",
       "3     interact__dummify__Division_E standardize__Hits      0.000000\n",
       "16                                       interact5__1      0.000000\n",
       "17                     interact5__dummify__Division_E      0.000000\n",
       "0                                         interact__1      0.000000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit lasso regression model on entire data set using this lambda = 10\n",
    "pipe_l_inter = top_model_interact(regression_label = \"lasso_reg\", type_of_regression = Lasso(alpha = 10))\n",
    "fitted_pipe_l_inter10 = pipe_l_inter.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_l_inter = fitted_pipe_l_inter10.named_steps[\"lasso_reg\"].coef_\n",
    "coeff_l_inter\n",
    "\n",
    "#ridge regression data frame of coefficients and their variable labels\n",
    "l_df_inter = variable_names_df(fitted_pipe_l_inter10, coeff_l_inter)\n",
    "l_df_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce1991f-8c56-4461-bd64-6e4c561f2477",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "268997ad-52bb-4549-8f42-1072f0c90246",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+07, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.499e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+07, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.483e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+07, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+07, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.462e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+07, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.445e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+07, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+07, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.091e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+07, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.072e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+07, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.695e+06, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.355e+06, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+06, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.624e+06, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.520e+06, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e+05, tolerance: 4.708e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+05, tolerance: 3.606e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.355e+04, tolerance: 4.137e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e+05, tolerance: 4.281e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e+05, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.006e+03, tolerance: 4.558e+03\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 125.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'l1_ratio' parameter of ElasticNet must be a float in the range [0.0, 1.0]. Got 10 instead.\n",
      "\n",
      "/Users/conniechou/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [-131927.92652017 -131946.61384    -132138.9400008  -134880.66618804\n",
      "              nan -125858.27782676 -125882.77031152 -126141.64389949\n",
      " -134786.2662439               nan -119803.75482191 -119827.0729764\n",
      " -120073.85676265 -133865.80776012              nan -117715.06339379\n",
      " -117678.31990037 -117335.33654493 -129431.04105964              nan\n",
      " -159991.26511971 -159766.91087339 -157388.10576969 -121693.61279416\n",
      "              nan]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_elastic_net__alpha</th>\n",
       "      <th>param_elastic_net__l1_ratio</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>117335.336545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>117678.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>117715.063394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>119803.754822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>119827.072976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>120073.856763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>121693.612794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>125858.277827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>125882.770312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>126141.643899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>129431.041060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>131927.926520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>131946.613840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>132138.940001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>133865.807760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>134786.266244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>134880.666188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>157388.105770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>159766.910873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>159991.265120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_elastic_net__alpha param_elastic_net__l1_ratio  mean_test_score\n",
       "17                        1                         0.1    117335.336545\n",
       "16                        1                        0.01    117678.319900\n",
       "15                        1                       0.001    117715.063394\n",
       "10                      0.1                       0.001    119803.754822\n",
       "11                      0.1                        0.01    119827.072976\n",
       "12                      0.1                         0.1    120073.856763\n",
       "23                       10                           1    121693.612794\n",
       "5                      0.01                       0.001    125858.277827\n",
       "6                      0.01                        0.01    125882.770312\n",
       "7                      0.01                         0.1    126141.643899\n",
       "18                        1                           1    129431.041060\n",
       "0                     0.001                       0.001    131927.926520\n",
       "1                     0.001                        0.01    131946.613840\n",
       "2                     0.001                         0.1    132138.940001\n",
       "13                      0.1                           1    133865.807760\n",
       "8                      0.01                           1    134786.266244\n",
       "3                     0.001                           1    134880.666188\n",
       "22                       10                         0.1    157388.105770\n",
       "21                       10                        0.01    159766.910873\n",
       "20                       10                       0.001    159991.265120\n",
       "4                     0.001                          10              NaN\n",
       "9                      0.01                          10              NaN\n",
       "14                      0.1                          10              NaN\n",
       "19                        1                          10              NaN\n",
       "24                       10                          10              NaN"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elastic net regression model fitting\n",
    "\n",
    "pipe_inter_en = top_model_interact(\"elastic_net\", ElasticNet())\n",
    "\n",
    "param = {'elastic_net__alpha': lambdas_list,\n",
    "          \"elastic_net__l1_ratio\" : alpha_list}\n",
    "\n",
    "#running girdsearchcv to tune to different lambda values\n",
    "gscv_inter_en = GridSearchCV(pipe_inter_en, param, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "#fitting gridsearchcv to entire dataset\n",
    "gscv_fitted_inter_en = gscv_inter_en.fit(X, y)\n",
    "\n",
    "#creating dataframe for mse values and lambda values\n",
    "en_df_inter = pd.DataFrame(gscv_fitted_inter_en.cv_results_)\n",
    "en_df_inter = en_df_inter[[\"param_elastic_net__alpha\", \"param_elastic_net__l1_ratio\", \"mean_test_score\"]] #get the columns i want\n",
    "en_df_inter[\"mean_test_score\"] = en_df_inter[\"mean_test_score\"].abs() #absolute value of mean square errors\n",
    "en_df_inter.sort_values(by = \"mean_test_score\", ascending = True) #sort mse values, want smallest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3472b1c-6f3b-4884-825c-7bb69efee992",
   "metadata": {},
   "source": [
    "### The model where lambda = 1 and alpha = 0.1 is the best. The MSE is 117335.336545."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d707af9-bcfb-409c-84d5-1e76aaf66cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>interact4__standardize__CRBI</td>\n",
       "      <td>53.040434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interact__standardize__Hits</td>\n",
       "      <td>51.084824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>interact3__standardize__CHits</td>\n",
       "      <td>45.210430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interact2__standardize__CRuns</td>\n",
       "      <td>44.936364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>interact5__standardize__Walks</td>\n",
       "      <td>42.871207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>interact4__dummify__Division_E standardize__CRBI</td>\n",
       "      <td>32.947048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>interact5__dummify__Division_E standardize__Walks</td>\n",
       "      <td>29.979180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interact__dummify__Division_E standardize__Hits</td>\n",
       "      <td>29.090709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>interact2__dummify__Division_E standardize__CRuns</td>\n",
       "      <td>24.531806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>interact3__dummify__Division_E standardize__CHits</td>\n",
       "      <td>22.107797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interact__dummify__Division_E</td>\n",
       "      <td>16.566807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>interact5__dummify__Division_E</td>\n",
       "      <td>16.566784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>interact4__dummify__Division_E</td>\n",
       "      <td>16.566776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interact2__dummify__Division_E</td>\n",
       "      <td>16.566776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>interact3__dummify__Division_E</td>\n",
       "      <td>16.566750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interact3__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>interact4__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interact2__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>interact5__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interact__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        variable_name  coefficients\n",
       "14                       interact4__standardize__CRBI     53.040434\n",
       "2                         interact__standardize__Hits     51.084824\n",
       "10                      interact3__standardize__CHits     45.210430\n",
       "6                       interact2__standardize__CRuns     44.936364\n",
       "18                      interact5__standardize__Walks     42.871207\n",
       "15   interact4__dummify__Division_E standardize__CRBI     32.947048\n",
       "19  interact5__dummify__Division_E standardize__Walks     29.979180\n",
       "3     interact__dummify__Division_E standardize__Hits     29.090709\n",
       "7   interact2__dummify__Division_E standardize__CRuns     24.531806\n",
       "11  interact3__dummify__Division_E standardize__CHits     22.107797\n",
       "1                       interact__dummify__Division_E     16.566807\n",
       "17                     interact5__dummify__Division_E     16.566784\n",
       "13                     interact4__dummify__Division_E     16.566776\n",
       "5                      interact2__dummify__Division_E     16.566776\n",
       "9                      interact3__dummify__Division_E     16.566750\n",
       "8                                        interact3__1      0.000000\n",
       "12                                       interact4__1      0.000000\n",
       "4                                        interact2__1      0.000000\n",
       "16                                       interact5__1      0.000000\n",
       "0                                         interact__1      0.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit elastic net regression model on entire data set using this lambda = 0.1, alpha = 0.001.\n",
    "pipe_en_inter = top_model_interact(regression_label = \"elastic_net\", type_of_regression = ElasticNet(alpha = 1, l1_ratio = 0.1))\n",
    "fitted_pipe_en_inter = pipe_en_inter.fit(X, y)\n",
    "\n",
    "#coefficients for fitted ridge pipeline\n",
    "coeff_en_inter = fitted_pipe_en_inter.named_steps[\"elastic_net\"].coef_\n",
    "coeff_en_inter\n",
    "\n",
    "#ridge regression data frame of coefficients and their variable labels\n",
    "en_df_inter = variable_names_df(fitted_pipe_en_inter, coeff_en_inter)\n",
    "en_df_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110c602-caf6-4b4b-8394-b0f5c59c9c4b",
   "metadata": {},
   "source": [
    "# Part 3: Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd125c-8d98-4489-ad0c-ff91aff2a504",
   "metadata": {},
   "source": [
    "### Ridge: Compare your Ridge models with your ordinary regression models. How did your coefficients compare? Why does this make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1105c2c-58eb-4af8-8894-519b0fbcd584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>320.412169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>296.645050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>160.386784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>126.659607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>124.407173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variable_name  coefficients\n",
       "16  standardize__CRuns    320.412169\n",
       "7    standardize__Hits    296.645050\n",
       "17   standardize__CRBI    160.386784\n",
       "14  standardize__CHits    126.659607\n",
       "11  standardize__Walks    124.407173"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ordinary ridge model coefficients\n",
    "r_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0195dd5-4109-4b02-bb7d-f272ae04d16a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190.28270194])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefficient with just one numerical variable: Hits\n",
    "coeff_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c2a7e4a-3230-48ed-bf4b-2072891bd0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standardize__CRBI</td>\n",
       "      <td>126.472957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standardize__Hits</td>\n",
       "      <td>104.861189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>standardize__Walks</td>\n",
       "      <td>69.846563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standardize__CRuns</td>\n",
       "      <td>57.286936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standardize__CHits</td>\n",
       "      <td>26.383317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        variable_name  coefficients\n",
       "3   standardize__CRBI    126.472957\n",
       "0   standardize__Hits    104.861189\n",
       "4  standardize__Walks     69.846563\n",
       "1  standardize__CRuns     57.286936\n",
       "2  standardize__CHits     26.383317"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefficients with top 5 numerical variables\n",
    "r_df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a781dc06-d2ad-41d8-a709-69a2ef31848f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>interact4__dummify__Division_E standardize__CRBI</td>\n",
       "      <td>107.257033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>interact4__standardize__CRBI</td>\n",
       "      <td>94.534228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interact__standardize__Hits</td>\n",
       "      <td>84.696145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>interact3__standardize__CHits</td>\n",
       "      <td>53.076194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>interact5__dummify__Division_E standardize__Walks</td>\n",
       "      <td>49.076620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        variable_name  coefficients\n",
       "15   interact4__dummify__Division_E standardize__CRBI    107.257033\n",
       "14                       interact4__standardize__CRBI     94.534228\n",
       "2                         interact__standardize__Hits     84.696145\n",
       "10                      interact3__standardize__CHits     53.076194\n",
       "19  interact5__dummify__Division_E standardize__Walks     49.076620"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefficients with top 5 numerical variables and top categorical variable\n",
    "r_df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96252e93-9f73-4de1-83c2-d994f3a3576f",
   "metadata": {},
   "source": [
    "The coefficients for the variables in the ordinary regression model that includes all of the variables are much higher than the coefficients in the other regression models that limited which variables to include in the model. The limited ridge regression models's coefficients are also smaller than the coefficients for all of the ordinary regression models (linear, lasso, and elastic net). This makes sense because in an ordinary regression model, the coefficients are large, meaning that the model is too flexible, so it is overfitting. Predicted values are sensitive to small changes in the variables x in an ordinary regression model. With ridge regression, however, it prevents this sensitive change by implementing a ridge penalty. It makes the sum of squared errors small and the betas themselves small. By making these smaller, the \"line of best fit\" in a ridge regression are less likely to overfit and become sensitive to changes in the x variables, making the coefficients smaller. When the coefficients are smaller, the \"slope\" is smaller. A unit increase in x will thus lead to a smaller increase or decrease in y. This decreases the variance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013fabcc-de40-4593-a435-f1120728da05",
   "metadata": {},
   "source": [
    "### Lasso: Compare your LASSO model in I with your three LASSO models in II. Did you get the same lambda results? Why does this make sense? Did you get the same MSEs? Why does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d934dcc-6e3e-4904-8337-5c0138d391de",
   "metadata": {},
   "source": [
    "MSE for lasso model in part 1: 119761.59; lambda = 1\n",
    "MSE for lasso model in part 2 (1 numerical variable): 173061.63; lambda = 10\n",
    "MSE for lasso model in part 2 (5 numerical variables): 124607.22; lambda = 10\n",
    "MSE for lasso model in part 2 (5 numerical variables and interaction with categorical variable):121693.61; lambda = 10\n",
    "\n",
    "The lambda result for the model in part 1 is smaller than the lambda result for the models in part 2. This makes sense because the lambda value controls the amount of overfitting with a penalty. Since there are more variables in the model in part 1 compared to the model in part 2, the model was not overfitting severely. There were enough variables to create a fit that did not underfit or overfit and had the residuals that were small. However, in a dataset with less variables (like the models in part 2), there is a higher chance for overfitting. In a way, there is \"not enough data\" to make sure that the fit reduces the sum of squared residuals equally for both the training and testing data. There may be variance in the sum of squared residuals between the testing and training data. Thus, a higher lambda value is imposed to prevent overfitting by imposing a greater penalty. \n",
    "\n",
    "In regards to the MSEs, as the number of variables increase in my model, the MSE decreases. This makes sense because the model in part 1 has the most information to predict the response variable. With better predictions, the MSE decreases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d98f8-a9d0-4a63-b2d3-62ef0fc87c6c",
   "metadata": {},
   "source": [
    "### Elastic Net: Compare your MSEs for the Elastic Net models with those for the Ridge and LASSO models. Why does it make sense that Elastic Net always “wins”?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af6ad29-9227-4aa6-923e-3a116a3dde83",
   "metadata": {},
   "source": [
    "In all models, the elastic models has the smallest MSE; in other words, the elastic net models always \"wins.\" This makes sense because elastic net is a combination of ridge and lasso regression. It includes both penalties from ridge and lasso. It offers the best of both methods into one regression model, so there is a balance between feature selection and regularization, which can lead to better predictive performance. The lasso regression will shrink some unimportant coefficients to 0, which removes them from the model. The ridge regression will bring some coefficients to 0 but does not set them to 0, which handles multicollinearity and model stability. By providing the \"best of both worlds,\" the MSE will be lower in elastic net compared to Lasso and Ridge regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb2fe9-650f-49c3-a8c1-1575e61ac892",
   "metadata": {},
   "source": [
    "# Part 4: Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def0915f-fc21-4733-925c-20e2b32f5b7d",
   "metadata": {},
   "source": [
    "## My best model is the one with the lowest MSE out of all of the models created. That model is the elastic net regression model with 5 numerical variables and an interaction with the Division categorical variable. The MSE is 117335.33, and the coefficients for each variable are listed below. These coefficients are also the smallest compared to the other models, since the elastic net regression has two penalties (one from ridge, another from lasso) to prevent overfitting. \n",
    "\n",
    "## The variables that affect the model the most are CRBI, Hits, CHits, CRuns, and Walks. These individual stats for baseball players have the most effect on their salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d573a9d-afb7-4aa2-ba33-90507662cd8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable_name</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>interact4__standardize__CRBI</td>\n",
       "      <td>53.040434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interact__standardize__Hits</td>\n",
       "      <td>51.084824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>interact3__standardize__CHits</td>\n",
       "      <td>45.210430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interact2__standardize__CRuns</td>\n",
       "      <td>44.936364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>interact5__standardize__Walks</td>\n",
       "      <td>42.871207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>interact4__dummify__Division_E standardize__CRBI</td>\n",
       "      <td>32.947048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>interact5__dummify__Division_E standardize__Walks</td>\n",
       "      <td>29.979180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interact__dummify__Division_E standardize__Hits</td>\n",
       "      <td>29.090709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>interact2__dummify__Division_E standardize__CRuns</td>\n",
       "      <td>24.531806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>interact3__dummify__Division_E standardize__CHits</td>\n",
       "      <td>22.107797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interact__dummify__Division_E</td>\n",
       "      <td>16.566807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>interact5__dummify__Division_E</td>\n",
       "      <td>16.566784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>interact4__dummify__Division_E</td>\n",
       "      <td>16.566776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interact2__dummify__Division_E</td>\n",
       "      <td>16.566776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>interact3__dummify__Division_E</td>\n",
       "      <td>16.566750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interact3__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>interact4__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interact2__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>interact5__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interact__1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        variable_name  coefficients\n",
       "14                       interact4__standardize__CRBI     53.040434\n",
       "2                         interact__standardize__Hits     51.084824\n",
       "10                      interact3__standardize__CHits     45.210430\n",
       "6                       interact2__standardize__CRuns     44.936364\n",
       "18                      interact5__standardize__Walks     42.871207\n",
       "15   interact4__dummify__Division_E standardize__CRBI     32.947048\n",
       "19  interact5__dummify__Division_E standardize__Walks     29.979180\n",
       "3     interact__dummify__Division_E standardize__Hits     29.090709\n",
       "7   interact2__dummify__Division_E standardize__CRuns     24.531806\n",
       "11  interact3__dummify__Division_E standardize__CHits     22.107797\n",
       "1                       interact__dummify__Division_E     16.566807\n",
       "17                     interact5__dummify__Division_E     16.566784\n",
       "13                     interact4__dummify__Division_E     16.566776\n",
       "5                      interact2__dummify__Division_E     16.566776\n",
       "9                      interact3__dummify__Division_E     16.566750\n",
       "8                                        interact3__1      0.000000\n",
       "12                                       interact4__1      0.000000\n",
       "4                                        interact2__1      0.000000\n",
       "16                                       interact5__1      0.000000\n",
       "0                                         interact__1      0.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coefficients\n",
    "en_df_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b19eebe-7daa-4f76-8eb3-1d176d539b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 480,
       "width": 640
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure Size: (640 x 480)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot comparing coefficients between best model (elastic net) and linear model with the 5 numerical var + division\n",
    "\n",
    "coefficient_df = pd.DataFrame({\"linear\": coeff_lr_inter,\n",
    "                               \"elastic_net\": coeff_en_inter})\n",
    "(ggplot(coefficient_df, aes(x = \"linear\", y = \"elastic_net\")) + geom_point() + ggtitle(\"Coefficients for Linear Regression and Elastic Net\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95faf1b-20a5-45a9-bbff-abf4bb265596",
   "metadata": {},
   "source": [
    "In this plot, we can see that there is a wide range in coefficient values for the linear model, but the range is smaller in the elastic net model. The elastic net model has been penalized, so some of the coefficients became 0, and some of the variables were brought closer to 0. That is why the coefficient values are smaller than the coefficient values in the linear regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
